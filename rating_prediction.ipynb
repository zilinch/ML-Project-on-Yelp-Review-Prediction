{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b48a5284",
   "metadata": {},
   "source": [
    "# Yelp Rating Prediction Model\n",
    "Project Source from: Offerbang, Chris\n",
    "\n",
    "Implementation: Zilin Chen\n",
    "\n",
    "Date: 7/26/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4b6907",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This project works on real yelp review data, and does data preprocessing and feature engineering using bag-of-words. The goal is to build and train a multi-class logistic regression model from scratch to predict customer's rating based on their reviews. And the model will be evaluated using both hard and soft metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeb55986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Tuple, Dict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a668f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the file path for each file\n",
    "\n",
    "#training set\n",
    "f_train = 'reviews_train.json'\n",
    "#validation set & label\n",
    "f_dev = 'reviews_dev.json'\n",
    "f_dev_labels = 'reviews_dev_labels.txt'\n",
    "#test set\n",
    "f_test = 'reviews_test.json'\n",
    "#stop words\n",
    "f_stop = 'stopword.list'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84807e0",
   "metadata": {},
   "source": [
    "### Data Preprocessing and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b853692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have implemented the stopwords loading for you\n",
    "def load_stopwords(infile: str) -> set:\n",
    "    with open(infile) as g:\n",
    "        stopwords = set(map(lambda x:x.strip(), g.readlines()))\n",
    "    print(f'{len(stopwords)} stopwords loaded')\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2971b317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341 stopwords loaded\n"
     ]
    }
   ],
   "source": [
    "# stopwords are non-useful words to be filtered out\n",
    "stopwords = load_stopwords(f_stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c1acd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete the parse_text function, the function takes one comment string\n",
    "#       and return a list of tokens(words)\n",
    "def parse_text(text: str) -> List[str]:\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
    "    \n",
    "    # TODO:\n",
    "    # 1. convert all tokens into lower case\n",
    "    # 2. remove tokens that in stopwords\n",
    "    # 3. remvoe empty token like ''\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        token = token.strip().lower()\n",
    "        if token and token not in stopwords:\n",
    "            tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aaa822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete preprocess function to load training/validation/test data from files\n",
    "#       if label_file is not None, you should read label from the label file, \n",
    "#       otherwise, load label from data file, \"text\" field in each json object. \n",
    "def preprocess(data_file: str, label_file: str=None) -> Tuple[List[List[str]], List[int]]:\n",
    "    review_list, star_list = [], []\n",
    "    \n",
    "    reviews = {}\n",
    "    stars = {}\n",
    "    with open(data_file, 'r') as f:\n",
    "        for json_str in f:\n",
    "            obj = json.loads(json_str)\n",
    "            # TODO: \n",
    "            # 1. load the reivew_id and reivew text from JSON obj, which\n",
    "            #   is a dictionary after loading to Python\n",
    "            # 2. using the parse_text function to process the review text\n",
    "            # 3. save the token list to review map: {review_id => tokens}\n",
    "            review_id = obj['review_id']\n",
    "            review = obj['text']\n",
    "            tokens = parse_text(review)\n",
    "            reviews[review_id] = tokens\n",
    "            \n",
    "            if label_file is None:\n",
    "                # TODO:\n",
    "                # 1. load the label (stars) from JSON obj\n",
    "                # 2. save tokens and star to output list (i.e., review_list, start_list)\n",
    "                star = int(obj['stars'])\n",
    "                review_list.append(tokens)\n",
    "                star_list.append(star)\n",
    "                \n",
    "    \n",
    "    if label_file:\n",
    "        # so we need to manually load stars from file\n",
    "        # file format: review_id<space>stars\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines:\n",
    "            review_id, star = line.strip().split()\n",
    "            stars[review_id] = int(star)\n",
    "\n",
    "        for review_id, tokens in reviews.items():\n",
    "            review_list.append(tokens)\n",
    "            star_list.append(stars[review_id])\n",
    "    \n",
    "    return review_list, star_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a048883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the training data\n",
    "review_list, star_list = preprocess(f_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a31bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1255353\n",
      "1255353\n"
     ]
    }
   ],
   "source": [
    "#review list should have the same length as star list\n",
    "assert len(review_list) == len(star_list)\n",
    "\n",
    "print(f'Number of training samples: {len(review_list)}')\n",
    "print(len(star_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0db9ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement this function to get the top 9 most frequent tokens\n",
    "def get_top_token_counts(review_list: List[List[str]]) -> List[Tuple[str, int]]:\n",
    "    \n",
    "    ct = Counter()\n",
    "    for token_list in review_list:\n",
    "        ct.update(token_list)\n",
    "    \n",
    "    token_cnt_list = sorted(ct.items(), key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    for token, cnt in token_cnt_list[:9]:\n",
    "        print(f'token={token}\\tcount={cnt}')\n",
    "    \n",
    "    # We will write the token and its count to a file just\n",
    "    # in case you need it :)\n",
    "    with open('token_counts.txt', 'w') as f:\n",
    "        for token, count in token_cnt_list:\n",
    "            f.write(f'{token} {count}\\n')\n",
    "    return token_cnt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "667f0477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token=good\tcount=721552\n",
      "token=place\tcount=706729\n",
      "token=food\tcount=673892\n",
      "token=great\tcount=573051\n",
      "token=like\tcount=542963\n",
      "token=just\tcount=518714\n",
      "token=time\tcount=433290\n",
      "token=service\tcount=411813\n",
      "token=really\tcount=385354\n"
     ]
    }
   ],
   "source": [
    "token_cnt_list = get_top_token_counts(review_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d82e1003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement this function to get the star distribution on traning set\n",
    "def get_label_counts(star_list: List[int]) -> List[int]:\n",
    "    stars_count = [0] * 5 # 1-5 stars\n",
    "    for star in star_list:\n",
    "        stars_count[star-1] += 1\n",
    "    \n",
    "    print('star counts:', stars_count)\n",
    "    print('distribution:', np.array(stars_count, dtype=float) / sum(stars_count))\n",
    "    return stars_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a750b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "star counts: [128038, 112547, 178215, 373469, 463084]\n",
      "distribution: [0.10199362 0.08965367 0.14196405 0.29750118 0.36888748]\n"
     ]
    }
   ],
   "source": [
    "stars_count = get_label_counts(star_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30a08181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_chart(labels, values, title, ylabel):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(labels, values)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60e1733b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_bar_chart(\n",
    "    labels=['1 Star', '2 Stars', '3 Stars', '4 Stars', '5 Stars'],\n",
    "    values=np.array(stars_count, dtype=float) / sum(stars_count),\n",
    "    title='Label (stars) distribution',\n",
    "    ylabel='Percentage'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b20502",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5ddae2",
   "metadata": {},
   "source": [
    "We use bag-of-words to construct features for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edf2f278",
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7e87588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the feature map where each token is mapped to a fixed index between 0-499.\n",
    "#       Also, make sure the token_cnt_list is sorted when you slice the top DICT_SIZE\n",
    "def create_feat_map(token_cnt_list: List[Tuple[str, int]], dict_size: int) -> Dict[str, int]:\n",
    "    feat_map = {}\n",
    "    token_cnt_list.sort(key=lambda x:x[1], reverse=True)\n",
    "    for i in range(DICT_SIZE):\n",
    "        feat_map[token_cnt_list[i][0]] = i\n",
    "    \n",
    "    return feat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "291bcedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_map = create_feat_map(token_cnt_list, DICT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2696fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement the feature exatraction function to construct feature\n",
    "#       vector for the given review list\n",
    "def extract_feature(feat_map: Dict[str, int], review_list: List[List[str]]) -> np.ndarray:\n",
    "    n_sample, n_feat = len(review_list), DICT_SIZE\n",
    "    X = np.zeros((n_sample, n_feat))\n",
    "    for i, tokens in enumerate(review_list):\n",
    "        for token in tokens:\n",
    "            if token in feat_map:\n",
    "                X[i][feat_map[token]] += 1\n",
    "        \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee11ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the feature for train set\n",
    "X_train, y_train = extract_feature(feat_map, review_list), star_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "315c1b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the feature for validation set\n",
    "dev_review_list, dev_star_list = preprocess(f_dev, f_dev_labels)\n",
    "X_val, y_val = extract_feature(feat_map, dev_review_list), dev_star_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21ff84b",
   "metadata": {},
   "source": [
    "### Model Implementation: Multi-class Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8399d1b5",
   "metadata": {},
   "source": [
    "Letting $c\\in \\{1,2,3,...,C\\}$ be the class-label indicator, we estimate the probability of the class as:\n",
    "\n",
    "$$P(y=c|x;W)=\\frac{e^{w_c^Tx}}{\\sum_{c'=1}^C e^{w_{c'}^Tx}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec48af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first define our model parameter W and initialize it uniformly\n",
    "W = np.ones((5, DICT_SIZE)) / DICT_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb43e9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement this function to make prediction on one single instance, the output should be\n",
    "#       the probability of all different class (e.g., [0.1, 0.1, 0.6, 0.15, 0.05])\n",
    "def predict(W: np.ndarray, x: np.ndarray) -> np.ndarray:\n",
    "    wT_x = np.dot(W, x)\n",
    "    num = np.exp(wT_x)\n",
    "    scores = num / np.sum(num)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a842c8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2 0.2 0.2 0.2 0.2]\n"
     ]
    }
   ],
   "source": [
    "# Since each class has the same weight, your function should output \n",
    "# equal probability for any sample (e.g., [0.2 0.2 0.2 0.2 0.2])\n",
    "fake_x = np.zeros(DICT_SIZE)\n",
    "fake_x[DICT_SIZE-1] = 1.0\n",
    "scores = predict(W, fake_x)\n",
    "# y_i = convert_indicator(3)\n",
    "# diff = y_i - scores\n",
    "# print (diff.reshape((-1,1)))\n",
    "# print (fake_x.reshape(1,-1))\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6a029c",
   "metadata": {},
   "source": [
    "Given a training set of labeled pairs $D=\\{(x_i, y_i)\\}_{i=1}^n$, we optimize the model parameters as:\n",
    "\n",
    "$$W^* = \\arg\\max_W \\prod_{i=1}^n P(y_i|x_i;W)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f12902",
   "metadata": {},
   "source": [
    "We use L2 Regularization, and we can write our regularized loss function as:\n",
    "\n",
    "$$L(W)=-\\frac{1}{n}\\sum_{i=1}^n log P(y_i|x_i; W)+\\frac{\\lambda}{2}\\sum_{i=1}^C\\|w_i\\|^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa68b2",
   "metadata": {},
   "source": [
    "#### Get the gradient of loss function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db949818",
   "metadata": {},
   "source": [
    "In order to derive the gradient of our objective function (the regularized\n",
    "conditional log-likelihood), it is convenient to redefine the output label of i-th input (i.e., $y_i$ ) using a indicator vector $y_i=(y_{i1}, y_{i2},..., y_{iC})^T$, whose elements are defined as\n",
    "\n",
    "$$y_{ic}=\\begin{cases}\n",
    "1,& \\text{if } y_i=c\\\\\n",
    "    0,              & \\text{otherwise}\n",
    "\\end{cases} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e3cb7a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement the function to convert y=5 to indicator vector y_ind=[0,0,0,0,1]\n",
    "def convert_indicator(y: int) -> np.ndarray:\n",
    "    y_ind = np.zeros(5)\n",
    "    y_ind[y-1] = 1.0\n",
    "    return y_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "29cb3947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(convert_indicator(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291f965",
   "metadata": {},
   "source": [
    "Then the conditional probability of $y_i$ given $x_i$ and $W$ can be written as:\n",
    "$$P(y_i|x_i;W)=\\prod_{c=1}^C \\bigg(\\frac{e^{w_c^Tx_i}}{\\sum_{c'=1}^C e^{w_{c'}^Tx_i}} \\bigg)^{y_{ic}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933ddbc1",
   "metadata": {},
   "source": [
    "Now we want you to prove that the gradient of $L(W)$ with respect to vector $w_c$ (i.e., $\\frac{\\partial L(W)}{\\partial w_c}$) is equal to:\n",
    "\n",
    "$$-\\frac{1}{n}\\sum_{i=1}^n \\bigg(y_{ic}-\\frac{e^{w_c^Tx_i}}{\\sum_{c'=1}^C e^{w_{c'}^Tx_i}} \\bigg)x_i + \\lambda w_c$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1c2ed31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: implement the function to calculate gradient for W with a single sample\n",
    "#      so ignore the regularization part (\\lambda * w_c) for now\n",
    "def get_gradient(W: np.ndarray, x: np.ndarray, y: int) -> np.ndarray:\n",
    "    y_i = convert_indicator(y)\n",
    "    scores = predict(W, x)\n",
    "    diff = y_i - scores\n",
    "#     print (diff.shape, x.shape)\n",
    "    grad = np.dot(diff.reshape((-1,1)), x.reshape(1,-1))    \n",
    "    return -grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2b00adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement this function to perform one iteration of gradient descent\n",
    "#       on a given batch of data, where lr is the learning rate and regul \n",
    "#       is the regularization parameter\n",
    "def grad_update(W: np.ndarray, X_batch: List[np.ndarray], y_batch: List[int],\n",
    "                lr: float=0.01, regul:float=0.1) -> np.ndarray:\n",
    "\n",
    "    # the gradient should have the same shape as W\n",
    "    batch_grad = np.zeros_like(W)\n",
    "    \n",
    "    for x, y in zip(X_batch, y_batch):\n",
    "        grad = get_gradient(W, x, y)\n",
    "        batch_grad += grad\n",
    "    \n",
    "    batch_grad /= len(X_batch)\n",
    "    \n",
    "    W -= lr * batch_grad + regul * W\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6b892de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement this function to compute accuracy for a given dataset (X, y)\n",
    "def compute_accuracy(W: np.ndarray, X: np.ndarray, y: List[int]) -> None:\n",
    "    err = 0\n",
    "    for x, label in zip(X, y):\n",
    "        prob = predict(W, x)\n",
    "        y_i = prob.argmax() + 1 #find the true category\n",
    "        if y_i != label:\n",
    "            err += 1\n",
    "    print(f'Accuracy is {1.0 - err / len(X)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "55b1e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement this function to compute log-loss for a given dataset (X, y)\n",
    "def compute_loss(W: np.ndarray, X: np.ndarray, y: List[int], regul: float) -> None:\n",
    "    loss = 0\n",
    "    \n",
    "    for x, label in zip(X, y):\n",
    "        prob = predict(W, x)\n",
    "        max_prob_idx = prob.argmax()\n",
    "        loss += np.log(prob[max_prob_idx])\n",
    "    \n",
    "    loss = - loss / len(X) + regul * np.sum(np.square(W))  \n",
    "        \n",
    "    print(f'Loss is {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "10f5b21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use the tips above to complete this function for mini-batch GD model trainig\n",
    "def train_RMLR(X_train: np.ndarray, y_train: List[int], batch_size: int,\n",
    "               lr: float=0.01, regul:float =0.1) -> np.ndarray:\n",
    "    print('Start training RMLR...')\n",
    "    \n",
    "    # randomly initialize W, you can use np.random.rand\n",
    "    W = np.random.rand(5, DICT_SIZE)\n",
    "    \n",
    "    print('Initial performance')\n",
    "    compute_loss(W, X_train, y_train, regul)\n",
    "    compute_accuracy(W, X_val, y_val)\n",
    "    \n",
    "    n_batch = 0\n",
    "    batch_X = []\n",
    "    batch_y = []\n",
    "    \n",
    "    random_seq = [i for i in range(len(X_train))]\n",
    "    \n",
    "    while n_batch < 600: # add your stop criteria here\n",
    "        for idx in random_seq[:batch_size]:\n",
    "            # construct your mini-batch and start training\n",
    "            batch_X.append(X_train[idx])\n",
    "            batch_y.append(y_train[idx])\n",
    "            \n",
    "        W = grad_update(W, batch_X, batch_y, lr=lr, regul=regul)\n",
    "        n_batch += 1\n",
    "        batch_X = []\n",
    "        batch_y = []\n",
    "\n",
    "        if n_batch % 100 == 0:\n",
    "            print ('evaluate at batch', n_batch)\n",
    "            compute_loss(W, X_train, y_train, regul)\n",
    "            compute_accuracy(W, X_val, y_val)\n",
    "        \n",
    "        np.random.shuffle(random_seq)\n",
    "                  \n",
    "    print('Training completed successfully!')\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6cae97e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training RMLR...\n",
      "Initial performance\n",
      "Loss is 84.0599757399288\n",
      "Accuracy is 0.18017323737341573\n",
      "evaluate at batch 100\n",
      "Loss is 1.5691270158418251\n",
      "Accuracy is 0.4361569326794472\n",
      "evaluate at batch 200\n",
      "Loss is 1.5694568604036918\n",
      "Accuracy is 0.4379593656455003\n",
      "evaluate at batch 300\n",
      "Loss is 1.569186091315034\n",
      "Accuracy is 0.4367237755556971\n",
      "evaluate at batch 400\n",
      "Loss is 1.5688868156057905\n",
      "Accuracy is 0.4351633653907394\n",
      "evaluate at batch 500\n",
      "Loss is 1.5694706217134313\n",
      "Accuracy is 0.4349468186739698\n",
      "evaluate at batch 600\n",
      "Loss is 1.5697321729327034\n",
      "Accuracy is 0.4342462263550092\n",
      "Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "W = train_RMLR(X_train, y_train, batch_size=10000, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bed7eed",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5fb420",
   "metadata": {},
   "source": [
    "#### Hard Metrics\n",
    "We will use per-class accuracy and overall accuracy in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "68e76dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = [predict(W, x).argmax()+1 for x in X_train]\n",
    "y_pred_val = [predict(W, x).argmax()+1 for x in X_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a10a920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement the per-class accuracy and overall accuracy metrics, note\n",
    "#       here the input is true label list and predicted label list\n",
    "def multiclass_accuracy_score(y_true: List[int], y_pred: List[int]) -> None:\n",
    "    count = Counter()\n",
    "    err = Counter()\n",
    "    n_count, n_err = 0, 0\n",
    "    for y, y_hat in zip(y_true, y_pred):\n",
    "        count[y] += 1\n",
    "        n_count += 1\n",
    "        if y != y_hat:\n",
    "            err[y] += 1\n",
    "            n_err += 1\n",
    "    print(f'Overall accuracy: {1-n_err/n_count}')\n",
    "    print(f'Per-class accuracy:')\n",
    "    for star, cnt in sorted(count.items()):\n",
    "        print(f'Star={star}, accuracy={1-err[star]/cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e6b1e5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.43464029639471924\n",
      "Per-class accuracy:\n",
      "Star=1, accuracy=0.010356300473296942\n",
      "Star=2, accuracy=0.0\n",
      "Star=3, accuracy=0.0007406783940745454\n",
      "Star=4, accuracy=0.45186347461235066\n",
      "Star=5, accuracy=0.810677976349863\n",
      "Overall accuracy: 0.4342462263550092\n",
      "Per-class accuracy:\n",
      "Star=1, accuracy=0.010059097196026712\n",
      "Star=2, accuracy=0.0\n",
      "Star=3, accuracy=0.0005799687709123758\n",
      "Star=4, accuracy=0.45294928691455905\n",
      "Star=5, accuracy=0.8073374001202852\n"
     ]
    }
   ],
   "source": [
    "multiclass_accuracy_score(y_train, y_pred_train)\n",
    "multiclass_accuracy_score(y_val, y_pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3207ce9",
   "metadata": {},
   "source": [
    "#### Soft metrics\n",
    "The soft metric is the Root Mean Square Error (RMSE) for your prediction results, which is defined as\n",
    "\n",
    "$$\\text{RMSE}=\\sqrt{\\frac{1}{n}\\sum_{i=1}^n(\\hat{r}_i-r_i)^2}$$\n",
    "\n",
    "where $\\hat{r}_i$ is your predicted rating for i-th instance, $r_i$ is the corresponding true rating and $n$ is the size of dataset used for testing. The soft metric shows the average difference between your predictions and true ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3f8aa3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement the function to evaluate RMSE, here the input is also\n",
    "#       two list of labels (true & predicted)\n",
    "def root_mean_square_err(y_true: List[int], y_pred: List[int]) -> None:\n",
    "    s = 0.0\n",
    "    for y, y_hat in zip(y_true, y_pred):\n",
    "        s += np.square(y_hat - y)\n",
    "\n",
    "    print(f'RMSE={np.sqrt(s / len(y_true))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "844f30d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE=1.5816439417944188\n",
      "RMSE=1.578009911021339\n"
     ]
    }
   ],
   "source": [
    "root_mean_square_err(y_train, y_pred_train)\n",
    "root_mean_square_err(y_val, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eab312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
